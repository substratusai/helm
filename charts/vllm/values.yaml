replicaCount: 1
# Change this if you want to serve another model
model: mistralai/Mistral-7B-Instruct-v0.1
servedModelName: "" # optional, defaults to model name
quantization: "" # optional, choose awq or squeezellm
dtype: "" # optional, only required to be set to half when using awq for quantization
gpuMemoryUtilization: "" # Optional, default is 0.90

# this only works on GKE today
readManyPVC:
  enabled: false
  # provide the name of the PVC that has the model
  sourcePVC: ""
  accessModes:
  - ReadOnlyMany
  mountPath: /model
  size: 30Gi
  # storageClass needs to match the sourcePVC storageClass
  storageClass: ""

deploymentAnnotations: {}

# Override the resources if you need more
resources:
  requests:
    cpu: 500m
    memory: "512Mi"
  limits:
    nvidia.com/gpu: 1


# Override env variables
env: {}
port: 8080

# Add nodeSelectors to target specific GPU types
nodeSelector: {}
#  E.g. for GCP L4 cloud.google.com/gke-accelerator: nvidia-l4

image:
  repository: substratusai/vllm
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

podAnnotations: {}

podSecurityContext: {}

securityContext: {}

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

tolerations: []

affinity: {}
