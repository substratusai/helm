# This example requires first running
# `kubectl apply -f load-model-job-mistral-7b-instruct.yaml` to load the model into a PVC.
model: /model
servedModelName: mistral-7b-instruct-v0.1

replicaCount: 0

deploymentAnnotations:
  lingo.substratus.ai/models: mistral-7b-instruct-v0.1
  lingo.substratus.ai/min-replicas: "0" # needs to be string
  lingo.substratus.ai/max-replicas: "3" # needs to be string

readManyPVC:
  enabled: true
  sourcePVC: "mistral-7b-instruct"
  mountPath: /model
  size: 20Gi

nodeSelector:
  cloud.google.com/gke-accelerator: nvidia-l4

resources:
  requests:
    cpu: 7
    memory: 24Gi
    ephemeral-storage: 10Gi
  limits:
    nvidia.com/gpu: 1
